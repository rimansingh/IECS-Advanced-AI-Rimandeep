{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import gin\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from mltrainer import rnn_models, Trainer\n",
    "from torch import optim\n",
    "\n",
    "from mads_datasets import datatools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Iterators\n",
    "We will be using an interesting dataset. [link](https://tev.fbk.eu/resources/smartwatch)\n",
    "\n",
    "From the site:\n",
    "> The SmartWatch Gestures Dataset has been collected to evaluate several gesture recognition algorithms for interacting with mobile applications using arm gestures. Eight different users performed twenty repetitions of twenty different gestures, for a total of 3200 sequences. Each sequence contains acceleration data from the 3-axis accelerometer of a first generation Sony SmartWatch™, as well as timestamps from the different clock sources available on an Android device. The smartwatch was worn on the user's right wrist. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-09 19:19:05.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/gestures\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 2600/2600 [00:07<00:00, 368.01it/s]\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 651/651 [00:01<00:00, 390.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import PaddedPreprocessor\n",
    "preprocessor = PaddedPreprocessor()\n",
    "\n",
    "gesturesdatasetfactory = DatasetFactoryProvider.create_factory(DatasetType.GESTURES)\n",
    "streamers = gesturesdatasetfactory.create_datastreamer(batchsize=32, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 20)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 25, 3]),\n",
       " tensor([12, 12,  2, 16, 12, 18,  9,  6,  4,  2, 12, 10,  2, 14,  5,  9, 19,  4,\n",
       "         11,  8,  8, 18,  7, 10, 12, 18,  4, 15,  0,  3,  9, 13]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "x, y = next(iter(trainstreamer))\n",
    "x.shape, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you make sense of the shape?\n",
    "What does it mean that the shapes are sometimes (32, 27, 3), but a second time might look like (32, 30, 3)? In other words, the second (or first, if you insist on starting at 0) dimension changes. Why is that? How does the model handle this? Do you think this is already padded, or still has to be padded?\n",
    "\n",
    "\n",
    "# 2 Excercises\n",
    "Lets test a basemodel, and try to improve upon that.\n",
    "\n",
    "Fill the gestures.gin file with relevant settings for `input_size`, `hidden_size`, `num_layers` and `horizon` (which, in our case, will be the number of classes...)\n",
    "\n",
    "As a rule of thumbs: start lower than you expect to need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epochs: 50\n",
       "metrics: [Accuracy]\n",
       "logdir: gestures\n",
       "train_steps: 81\n",
       "valid_steps: 20\n",
       "reporttypes: [<ReportTypes.GIN: 1>, <ReportTypes.TENSORBOARD: 2>, <ReportTypes.MLFLOW: 3>]\n",
       "optimizer_kwargs: {'lr': 0.001, 'weight_decay': 1e-05}\n",
       "scheduler_kwargs: {'factor': 0.5, 'patience': 5}\n",
       "earlystop_kwargs: None"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mltrainer import TrainerSettings, ReportTypes\n",
    "from mltrainer.metrics import Accuracy\n",
    "\n",
    "accuracy = Accuracy()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=50,\n",
    "    metrics=[accuracy],\n",
    "    logdir=Path(\"gestures\"),\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.GIN, ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5},\n",
    "    earlystop_kwargs=None\n",
    ")\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.parse_config_file(\"gestures.gin\")\n",
    "model = rnn_models.BaseRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 3, 'hidden_size': 32, 'num_layers': 2, 'horizon': 20}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gin.get_bindings(\"BaseRNN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model. What is the output shape you need? Remember, we are doing classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model(x)\n",
    "yhat.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Accuracy: 0.03125\n"
     ]
    }
   ],
   "source": [
    "accuracy = Accuracy()\n",
    "acc_value = accuracy(y, yhat)\n",
    "print(f\"Initial Accuracy: {acc_value}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of the accuracy? What would you expect from blind guessing?\n",
    "\n",
    "Check shape of `y` and `yhat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 20]), torch.Size([32]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And look at the output of yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3014,  0.0815,  0.2321, -0.1648, -0.2833, -0.2129, -0.1003, -0.2096,\n",
      "         0.0835,  0.2973, -0.0101,  0.0977, -0.0847,  0.2912,  0.2653, -0.1393,\n",
      "         0.0459, -0.1831,  0.0101, -0.2581], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(yhat[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this make sense to you? If you are unclear, go back to the classification problem with the MNIST, where we had 10 classes.\n",
    "\n",
    "We have a classification problem, so we need Cross Entropy Loss.\n",
    "Remember, [this has a softmax built in](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Loss: 3.006039619445801\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss = loss_fn(yhat, y)\n",
    "print(f\"Initial Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 3, 'hidden_size': 32, 'num_layers': 2, 'horizon': 20}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gin.get_bindings(\"BaseRNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")\n",
    "\n",
    "# on my mac, at least for the BaseRNN model, mps does not speed up training\n",
    "# probably because the overhead of copying the data to the GPU is too high\n",
    "# however, it might speed up training for larger models, with more parameters\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-09 19:19:16.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to gestures/20250309-191916\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 46.11it/s]\n",
      "\u001b[32m2025-03-09 19:19:18.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 2.9736 test 2.8433 metric ['0.0875']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 78.65it/s]\n",
      "\u001b[32m2025-03-09 19:19:19.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 2.5808 test 2.4544 metric ['0.0891']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 66.67it/s]\n",
      "\u001b[32m2025-03-09 19:19:20.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 2.4731 test 2.4710 metric ['0.0969']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 73.92it/s]\n",
      "\u001b[32m2025-03-09 19:19:21.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 2.4348 test 2.4072 metric ['0.1125']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 58.85it/s]\n",
      "\u001b[32m2025-03-09 19:19:23.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 2.3836 test 2.3777 metric ['0.1594']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:00<00:00, 85.48it/s]\n",
      "\u001b[32m2025-03-09 19:19:24.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 5 train 2.3174 test 2.2715 metric ['0.1656']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 68.48it/s]\n",
      "\u001b[32m2025-03-09 19:19:26.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 6 train 2.2551 test 2.1965 metric ['0.2313']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:00<00:00, 86.49it/s]\n",
      "\u001b[32m2025-03-09 19:19:27.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 7 train 2.2169 test 2.1781 metric ['0.1922']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 71.96it/s]\n",
      "\u001b[32m2025-03-09 19:19:28.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 8 train 2.1958 test 2.2043 metric ['0.2094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:00<00:00, 89.39it/s]\n",
      "\u001b[32m2025-03-09 19:19:29.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 9 train 2.2230 test 2.1854 metric ['0.2109']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 49.46it/s]\n",
      "\u001b[32m2025-03-09 19:19:31.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 10 train 2.2474 test 2.1371 metric ['0.2250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 50.43it/s]\n",
      "\u001b[32m2025-03-09 19:19:33.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 11 train 2.1638 test 2.1624 metric ['0.2141']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 80.18it/s]\n",
      "\u001b[32m2025-03-09 19:19:35.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 12 train 2.1203 test 2.1067 metric ['0.2156']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 77.09it/s]\n",
      "\u001b[32m2025-03-09 19:19:36.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 13 train 2.1649 test 2.1128 metric ['0.2156']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 31.32it/s]\n",
      "\u001b[32m2025-03-09 19:19:39.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 14 train 2.2558 test 2.4737 metric ['0.1422']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 73.77it/s]\n",
      "\u001b[32m2025-03-09 19:19:40.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 15 train 2.3465 test 2.2566 metric ['0.1688']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:00<00:00, 81.26it/s]\n",
      "\u001b[32m2025-03-09 19:19:42.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 16 train 2.2773 test 2.1337 metric ['0.2406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 41.04it/s]\n",
      "\u001b[32m2025-03-09 19:19:44.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 17 train 2.1262 test 2.0790 metric ['0.2094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 67.88it/s]\n",
      "\u001b[32m2025-03-09 19:19:45.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 18 train 2.1126 test 2.0698 metric ['0.2266']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 70.94it/s]\n",
      "\u001b[32m2025-03-09 19:19:47.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 19 train 2.1037 test 2.0756 metric ['0.2250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 64.64it/s]\n",
      "\u001b[32m2025-03-09 19:19:48.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 20 train 2.0736 test 2.0813 metric ['0.2406']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 75.21it/s]\n",
      "\u001b[32m2025-03-09 19:19:49.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 21 train 2.0706 test 2.0599 metric ['0.2453']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 68.97it/s]\n",
      "\u001b[32m2025-03-09 19:19:51.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 22 train 2.0474 test 2.0296 metric ['0.2297']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:00<00:00, 84.57it/s]\n",
      "\u001b[32m2025-03-09 19:19:52.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 23 train 2.0410 test 2.0108 metric ['0.2641']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 66.14it/s]\n",
      "\u001b[32m2025-03-09 19:19:53.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 24 train 2.0329 test 2.0166 metric ['0.2609']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 67.39it/s]\n",
      "\u001b[32m2025-03-09 19:19:55.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 25 train 2.0459 test 2.0204 metric ['0.2781']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 65.37it/s]\n",
      "\u001b[32m2025-03-09 19:19:56.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 26 train 2.0722 test 2.1035 metric ['0.2094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:00<00:00, 84.56it/s]\n",
      "\u001b[32m2025-03-09 19:19:57.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 27 train 2.0952 test 2.1069 metric ['0.2313']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 67.38it/s]\n",
      "\u001b[32m2025-03-09 19:19:59.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 28 train 2.1039 test 2.0997 metric ['0.2391']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:00<00:00, 81.07it/s]\n",
      "\u001b[32m2025-03-09 19:20:00.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 29 train 2.0595 test 2.0505 metric ['0.2250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 77.42it/s]\n",
      "\u001b[32m2025-03-09 19:20:01.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 30 train 2.0536 test 1.9877 metric ['0.2359']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:00<00:00, 81.07it/s]\n",
      "\u001b[32m2025-03-09 19:20:02.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 31 train 2.0182 test 1.9680 metric ['0.2594']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 64.82it/s]\n",
      "\u001b[32m2025-03-09 19:20:04.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 32 train 2.0076 test 1.9638 metric ['0.2656']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 59.99it/s]\n",
      "\u001b[32m2025-03-09 19:20:06.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 33 train 1.9905 test 1.9832 metric ['0.2766']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:00<00:00, 89.68it/s]\n",
      "\u001b[32m2025-03-09 19:20:07.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 34 train 1.9788 test 1.9627 metric ['0.2687']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 69.99it/s]\n",
      "\u001b[32m2025-03-09 19:20:08.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 35 train 2.0045 test 1.9772 metric ['0.2781']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:00<00:00, 89.46it/s]\n",
      "\u001b[32m2025-03-09 19:20:09.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 36 train 1.9832 test 1.9579 metric ['0.2812']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 64.52it/s]\n",
      "\u001b[32m2025-03-09 19:20:10.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 37 train 2.0006 test 1.9880 metric ['0.2672']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:00<00:00, 81.23it/s]\n",
      "\u001b[32m2025-03-09 19:20:12.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 38 train 1.9873 test 1.9901 metric ['0.2594']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 58.92it/s]\n",
      "\u001b[32m2025-03-09 19:20:13.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 39 train 1.9992 test 1.9293 metric ['0.2859']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:00<00:00, 81.21it/s]\n",
      "\u001b[32m2025-03-09 19:20:15.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 40 train 1.9810 test 1.9710 metric ['0.2578']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 74.77it/s]\n",
      "\u001b[32m2025-03-09 19:20:16.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 41 train 1.9797 test 1.9516 metric ['0.2984']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 69.11it/s]\n",
      "\u001b[32m2025-03-09 19:20:17.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 42 train 1.9902 test 1.9624 metric ['0.2609']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:00<00:00, 90.28it/s]\n",
      "\u001b[32m2025-03-09 19:20:18.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 43 train 2.0124 test 1.9722 metric ['0.2734']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 67.23it/s]\n",
      "\u001b[32m2025-03-09 19:20:20.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 44 train 1.9694 test 1.9656 metric ['0.2766']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 77.50it/s]\n",
      "\u001b[32m2025-03-09 19:20:21.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 45 train 1.9918 test 1.9968 metric ['0.2781']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 63.56it/s]\n",
      "\u001b[32m2025-03-09 19:20:22.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 46 train 1.9764 test 1.9304 metric ['0.2797']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:00<00:00, 86.43it/s]\n",
      "\u001b[32m2025-03-09 19:20:24.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 47 train 1.9583 test 1.9367 metric ['0.3078']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 74.99it/s]\n",
      "\u001b[32m2025-03-09 19:20:25.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 48 train 1.9564 test 1.9533 metric ['0.2703']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 69.61it/s]\n",
      "\u001b[32m2025-03-09 19:20:26.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 49 train 1.9796 test 1.9285 metric ['0.2797']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 50/50 [01:10<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"gestures\")\n",
    "modeldir = Path(\"./models/gestures/\").resolve()\n",
    "if not modeldir.exists():\n",
    "    modeldir.mkdir(parents=True)\n",
    "\n",
    "gin.parse_config_file(\"gestures.gin\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"model\", \"BaseRNN\")\n",
    "    mlflow.set_tag(\"dev\", \"rimandeep\")\n",
    "    mlflow.log_params(gin.get_bindings(\"BaseRNN\"))\n",
    "\n",
    "    model = rnn_models.BaseRNN()\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        device=device,\n",
    "    )\n",
    "    trainer.loop()\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    model_path = modeldir / f\"{timestamp}_BaseRNN_model.pt\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    mlflow.log_artifact(str(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.16\n"
     ]
    }
   ],
   "source": [
    "from mltrainer.metrics import Accuracy\n",
    "\n",
    "accuracy = Accuracy()\n",
    "yhat = model(x)  # Get predictions from your trained model\n",
    "acc_value = accuracy(y, yhat)\n",
    "print(f\"Model Accuracy: {acc_value:.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to update the code above with the following two commands.\n",
    "    \n",
    "```python\n",
    "gin.parse_config_file('gestures_gru.gin')\n",
    "model = rnn_model.GRUmodel()\n",
    "```\n",
    "\n",
    "To discern between the changes, also modify the tag mlflow.set_tag(\"model\", \"new-tag-here\") where you add\n",
    "a new tag of your choice. This way you can keep the models apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-09 19:20:27.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to gestures/20250309-192027\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.62it/s]\n",
      "\u001b[32m2025-03-09 19:20:29.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 2.9973 test 2.9683 metric ['0.0891']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 31.11it/s]\n",
      "\u001b[32m2025-03-09 19:20:32.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 2.8989 test 2.7396 metric ['0.0984']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.58it/s]\n",
      "\u001b[32m2025-03-09 19:20:35.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 2.5496 test 2.4512 metric ['0.1109']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.42it/s]\n",
      "\u001b[32m2025-03-09 19:20:38.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 2.4101 test 2.3674 metric ['0.1766']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 34.17it/s]\n",
      "\u001b[32m2025-03-09 19:20:41.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 2.3423 test 2.3113 metric ['0.2016']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 34.41it/s]\n",
      "\u001b[32m2025-03-09 19:20:43.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 5 train 2.2888 test 2.2526 metric ['0.2172']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 37.55it/s]\n",
      "\u001b[32m2025-03-09 19:20:46.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 6 train 2.2147 test 2.1720 metric ['0.2188']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 36.32it/s]\n",
      "\u001b[32m2025-03-09 19:20:48.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 7 train 2.1276 test 2.0569 metric ['0.2812']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 38.97it/s]\n",
      "\u001b[32m2025-03-09 19:20:51.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 8 train 2.0430 test 1.9815 metric ['0.3203']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 33.42it/s]\n",
      "\u001b[32m2025-03-09 19:20:54.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 9 train 1.9564 test 1.8827 metric ['0.3484']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 36.42it/s]\n",
      "\u001b[32m2025-03-09 19:20:56.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 10 train 1.8547 test 1.7835 metric ['0.3937']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 33.19it/s]\n",
      "\u001b[32m2025-03-09 19:20:59.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 11 train 1.7755 test 1.7163 metric ['0.3594']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 41.29it/s]\n",
      "\u001b[32m2025-03-09 19:21:01.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 12 train 1.6741 test 1.6148 metric ['0.4359']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 33.07it/s]\n",
      "\u001b[32m2025-03-09 19:21:04.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 13 train 1.5869 test 1.5171 metric ['0.4562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 42.08it/s]\n",
      "\u001b[32m2025-03-09 19:21:06.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 14 train 1.5266 test 1.4413 metric ['0.5000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 38.59it/s]\n",
      "\u001b[32m2025-03-09 19:21:09.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 15 train 1.4599 test 1.4057 metric ['0.4922']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 39.15it/s]\n",
      "\u001b[32m2025-03-09 19:21:11.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 16 train 1.4015 test 1.3113 metric ['0.5484']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 34.57it/s]\n",
      "\u001b[32m2025-03-09 19:21:15.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 17 train 1.3279 test 1.3090 metric ['0.5391']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 39.39it/s]\n",
      "\u001b[32m2025-03-09 19:21:17.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 18 train 1.3033 test 1.2204 metric ['0.5687']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 36.34it/s]\n",
      "\u001b[32m2025-03-09 19:21:19.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 19 train 1.2365 test 1.1851 metric ['0.5844']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 36.21it/s]\n",
      "\u001b[32m2025-03-09 19:21:22.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 20 train 1.1952 test 1.1397 metric ['0.5766']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 34.81it/s]\n",
      "\u001b[32m2025-03-09 19:21:25.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 21 train 1.1622 test 1.0848 metric ['0.5969']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 34.38it/s]\n",
      "\u001b[32m2025-03-09 19:21:27.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 22 train 1.1269 test 1.0557 metric ['0.6359']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 24.46it/s]\n",
      "\u001b[32m2025-03-09 19:21:31.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 23 train 1.0804 test 1.0555 metric ['0.6188']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 21.81it/s]\n",
      "\u001b[32m2025-03-09 19:21:35.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 24 train 1.0727 test 1.0122 metric ['0.6297']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 29.74it/s]\n",
      "\u001b[32m2025-03-09 19:21:39.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 25 train 1.0130 test 0.9822 metric ['0.6469']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 18.30it/s]\n",
      "\u001b[32m2025-03-09 19:21:43.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 26 train 1.0145 test 0.9576 metric ['0.6609']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.51it/s]\n",
      "\u001b[32m2025-03-09 19:21:47.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 27 train 0.9666 test 0.9117 metric ['0.6766']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 24.50it/s]\n",
      "\u001b[32m2025-03-09 19:21:51.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 28 train 0.9433 test 0.8845 metric ['0.7078']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 31.55it/s]\n",
      "\u001b[32m2025-03-09 19:21:54.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 29 train 0.9035 test 0.8420 metric ['0.7188']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 23.13it/s]\n",
      "\u001b[32m2025-03-09 19:21:58.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 30 train 0.8849 test 0.8220 metric ['0.7266']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.29it/s]\n",
      "\u001b[32m2025-03-09 19:22:01.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 31 train 0.8638 test 0.8581 metric ['0.7016']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.30it/s]\n",
      "\u001b[32m2025-03-09 19:22:04.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 32 train 0.8361 test 0.8309 metric ['0.7281']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 34.56it/s]\n",
      "\u001b[32m2025-03-09 19:22:06.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 33 train 0.8171 test 0.8133 metric ['0.7281']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 33.55it/s]\n",
      "\u001b[32m2025-03-09 19:22:09.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 34 train 0.7837 test 0.8079 metric ['0.7297']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 35.22it/s]\n",
      "\u001b[32m2025-03-09 19:22:11.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 35 train 0.7821 test 0.7354 metric ['0.7562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 28.49it/s]\n",
      "\u001b[32m2025-03-09 19:22:15.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 36 train 0.7574 test 0.7093 metric ['0.7719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 31.69it/s]\n",
      "\u001b[32m2025-03-09 19:22:18.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 37 train 0.7314 test 0.7172 metric ['0.7781']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 34.17it/s]\n",
      "\u001b[32m2025-03-09 19:22:20.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 38 train 0.7057 test 0.6787 metric ['0.7781']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 37.48it/s]\n",
      "\u001b[32m2025-03-09 19:22:23.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 39 train 0.6835 test 0.6466 metric ['0.7875']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.52it/s]\n",
      "\u001b[32m2025-03-09 19:22:25.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 40 train 0.6593 test 0.6028 metric ['0.8078']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 36.70it/s]\n",
      "\u001b[32m2025-03-09 19:22:28.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 41 train 0.6514 test 0.6220 metric ['0.7969']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.39it/s]\n",
      "\u001b[32m2025-03-09 19:22:31.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 42 train 0.6281 test 0.6109 metric ['0.8000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 28.84it/s]\n",
      "\u001b[32m2025-03-09 19:22:34.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 43 train 0.6127 test 0.5707 metric ['0.8094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 34.42it/s]\n",
      "\u001b[32m2025-03-09 19:22:37.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 44 train 0.5899 test 0.5524 metric ['0.8172']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 35.45it/s]\n",
      "\u001b[32m2025-03-09 19:22:39.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 45 train 0.5953 test 0.5458 metric ['0.8219']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 34.58it/s]\n",
      "\u001b[32m2025-03-09 19:22:42.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 46 train 0.5815 test 0.5350 metric ['0.8281']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 31.29it/s]\n",
      "\u001b[32m2025-03-09 19:22:45.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 47 train 0.5518 test 0.5147 metric ['0.8297']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 34.91it/s]\n",
      "\u001b[32m2025-03-09 19:22:47.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 48 train 0.5463 test 0.5056 metric ['0.8391']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.55it/s]\n",
      "\u001b[32m2025-03-09 19:22:50.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 49 train 0.5429 test 0.5199 metric ['0.8266']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 50/50 [02:23<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import gin\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from mltrainer import Trainer, TrainerSettings, ReportTypes\n",
    "from mltrainer.metrics import Accuracy\n",
    "from mltrainer import rnn_models\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"gestures\")\n",
    "\n",
    "# Set modeldir to the 'models/gestures' folder in the current directory\n",
    "modeldir = Path.cwd() / \"models\" / \"gestures\"\n",
    "modeldir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gin.parse_config_file('gestures_gru.gin') \n",
    "\n",
    "model = rnn_models.GRUmodel()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "accuracy = Accuracy()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=50,\n",
    "    metrics=[accuracy],\n",
    "    logdir=Path(\"gestures\"),\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.GIN, ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5},\n",
    "    earlystop_kwargs=None\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Set a unique tag for this run\n",
    "    mlflow.set_tag(\"model\", \"GRUmodel\") \n",
    "    mlflow.set_tag(\"dev\", \"rimandeep\")\n",
    "    \n",
    "    mlflow.log_params(gin.get_bindings(\"GRUmodel\"))\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        device=device,\n",
    "    )\n",
    "    \n",
    "    trainer.loop()\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    model_path = modeldir / f\"{timestamp}_GRU_model.pt\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    mlflow.log_artifact(str(model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excercises:\n",
    "\n",
    "- improve the RNN model\n",
    "- test different things. What works? What does not?\n",
    "- experiment with either GRU or LSTM layers, create your own models + ginfiles. \n",
    "- experiment with adding Conv1D layers.\n",
    "\n",
    "You should be able to get above 90% accuracy with the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement and Train the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.LSTMModel"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gin\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "from mltrainer import Trainer, TrainerSettings, ReportTypes, metrics\n",
    "from mltrainer.preprocessors import PaddedPreprocessor\n",
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from torchinfo import summary\n",
    "\n",
    "# Define LSTM Model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        return self.fc(out)\n",
    "\n",
    "gin.external_configurable(LSTMModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-09 19:22:51.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/gestures\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 2600/2600 [00:06<00:00, 425.24it/s]\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 651/651 [00:01<00:00, 456.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Configuration loaded successfully.\n",
      "Gin Configuration Parameters:\n",
      "('', '__main__.LSTMModel')\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "preprocessor = PaddedPreprocessor()\n",
    "dataset_factory = DatasetFactoryProvider.create_factory(DatasetType.GESTURES)\n",
    "streamers = dataset_factory.create_datastreamer(batchsize=32, preprocessor=preprocessor)\n",
    "train_streamer, valid_streamer = streamers[\"train\"].stream(), streamers[\"valid\"].stream()\n",
    "\n",
    "# Set Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load Config\n",
    "gin.clear_config()\n",
    "gin.enter_interactive_mode()\n",
    "config_file = \"gestures_lstm.gin\"\n",
    "\n",
    "try:\n",
    "    gin.parse_config_file(config_file)\n",
    "    print(\"Configuration loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading config: {e}\")\n",
    "\n",
    "# Print Config Parameters\n",
    "print(\"Gin Configuration Parameters:\")\n",
    "for param in gin.config._CONFIG:\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "LSTMModel                                [32, 20]                  --\n",
      "├─LSTM: 1-1                              [32, 100, 64]             50,944\n",
      "├─Linear: 1-2                            [32, 20]                  1,300\n",
      "==========================================================================================\n",
      "Total params: 52,244\n",
      "Trainable params: 52,244\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 163.06\n",
      "==========================================================================================\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 1.64\n",
      "Params size (MB): 0.21\n",
      "Estimated Total Size (MB): 1.89\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Fetch Model Parameters from Config\n",
    "input_size = gin.query_parameter(\"LSTMModel.input_size\")\n",
    "hidden_size = gin.query_parameter(\"LSTMModel.hidden_size\")\n",
    "num_layers = gin.query_parameter(\"LSTMModel.num_layers\")\n",
    "dropout = gin.query_parameter(\"LSTMModel.dropout\")\n",
    "num_classes = gin.query_parameter(\"LSTMModel.num_classes\")\n",
    "\n",
    "# Initialize Model\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, num_classes, dropout).to(device)\n",
    "print(summary(model, input_size=(32, 100, input_size)))  # Display Model Summary\n",
    "\n",
    "# Define Optimizer & Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5)\n",
    "\n",
    "# Trainer Settings\n",
    "settings = TrainerSettings(\n",
    "    epochs=30,\n",
    "    metrics=[metrics.Accuracy()],\n",
    "    logdir=Path(\"gestures\"),\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.GIN, ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 5},\n",
    "    earlystop_kwargs={\"patience\": 5},\n",
    "    optimizer_kwargs={\"lr\": 0.001}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-09 19:23:00.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to gestures/20250309-192300\u001b[0m\n",
      "\u001b[32m2025-03-09 19:23:00.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 25.95it/s]\n",
      "\u001b[32m2025-03-09 19:23:03.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 2.7834 test 2.3210 metric ['0.1984']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.24it/s]\n",
      "\u001b[32m2025-03-09 19:23:06.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 2.1895 test 2.0525 metric ['0.2781']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 24.67it/s]\n",
      "\u001b[32m2025-03-09 19:23:11.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 1.9194 test 1.7238 metric ['0.3141']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:06<00:00, 12.51it/s]\n",
      "\u001b[32m2025-03-09 19:23:17.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 1.7549 test 1.7341 metric ['0.3359']\u001b[0m\n",
      "\u001b[32m2025-03-09 19:23:17.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 1.7238, current loss 1.7341.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 34.83it/s]\n",
      "\u001b[32m2025-03-09 19:23:20.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 1.5960 test 1.5440 metric ['0.4219']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 27.21it/s]\n",
      "\u001b[32m2025-03-09 19:23:23.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 5 train 1.3477 test 1.1755 metric ['0.4719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 31.59it/s]\n",
      "\u001b[32m2025-03-09 19:23:26.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 6 train 1.2200 test 1.1394 metric ['0.4938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 38.16it/s]\n",
      "\u001b[32m2025-03-09 19:23:29.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 7 train 1.1188 test 0.9965 metric ['0.5297']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 37.58it/s]\n",
      "\u001b[32m2025-03-09 19:23:31.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 8 train 0.9992 test 0.9356 metric ['0.5781']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 37.90it/s]\n",
      "\u001b[32m2025-03-09 19:23:34.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 9 train 0.9366 test 0.8725 metric ['0.6047']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 29.22it/s]\n",
      "\u001b[32m2025-03-09 19:23:37.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 10 train 0.9400 test 0.7870 metric ['0.6562']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 35.41it/s]\n",
      "\u001b[32m2025-03-09 19:23:40.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 11 train 0.7521 test 0.7078 metric ['0.6859']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 26.50it/s]\n",
      "\u001b[32m2025-03-09 19:23:43.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 12 train 0.6888 test 0.5784 metric ['0.7500']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 27.48it/s]\n",
      "\u001b[32m2025-03-09 19:23:47.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 13 train 0.5965 test 0.6077 metric ['0.7422']\u001b[0m\n",
      "\u001b[32m2025-03-09 19:23:47.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.5784, current loss 0.6077.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.67it/s]\n",
      "\u001b[32m2025-03-09 19:23:53.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 14 train 0.5170 test 0.4599 metric ['0.8125']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.65it/s]\n",
      "\u001b[32m2025-03-09 19:23:57.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 15 train 0.4903 test 0.4567 metric ['0.8047']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 29.38it/s]\n",
      "\u001b[32m2025-03-09 19:24:00.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 16 train 0.4025 test 0.3857 metric ['0.8422']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 28.82it/s]\n",
      "\u001b[32m2025-03-09 19:24:03.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 17 train 0.3603 test 0.3302 metric ['0.8797']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 32.75it/s]\n",
      "\u001b[32m2025-03-09 19:24:06.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 18 train 0.3141 test 0.2884 metric ['0.9109']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 36.06it/s]\n",
      "\u001b[32m2025-03-09 19:24:09.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 19 train 0.2914 test 0.2973 metric ['0.9078']\u001b[0m\n",
      "\u001b[32m2025-03-09 19:24:09.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.2884, current loss 0.2973.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 37.02it/s]\n",
      "\u001b[32m2025-03-09 19:24:11.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 20 train 0.2680 test 0.3007 metric ['0.8906']\u001b[0m\n",
      "\u001b[32m2025-03-09 19:24:11.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.2884, current loss 0.3007.Counter 2/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 38.26it/s]\n",
      "\u001b[32m2025-03-09 19:24:14.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 21 train 0.2008 test 0.2008 metric ['0.9484']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 39.05it/s]\n",
      "\u001b[32m2025-03-09 19:24:16.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 22 train 0.1845 test 0.1964 metric ['0.9437']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 44.56it/s]\n",
      "\u001b[32m2025-03-09 19:24:18.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 23 train 0.1440 test 0.1786 metric ['0.9531']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 41.56it/s]\n",
      "\u001b[32m2025-03-09 19:24:21.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 24 train 0.1423 test 0.1305 metric ['0.9688']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:01<00:00, 42.95it/s]\n",
      "\u001b[32m2025-03-09 19:24:23.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 25 train 0.1344 test 0.1047 metric ['0.9781']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 38.37it/s]\n",
      "\u001b[32m2025-03-09 19:24:26.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 26 train 0.0967 test 0.1046 metric ['0.9781']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 39.60it/s]\n",
      "\u001b[32m2025-03-09 19:24:28.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 27 train 0.0753 test 0.1149 metric ['0.9766']\u001b[0m\n",
      "\u001b[32m2025-03-09 19:24:28.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.1046, current loss 0.1149.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 36.74it/s]\n",
      "\u001b[32m2025-03-09 19:24:30.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 28 train 0.0667 test 0.0837 metric ['0.9812']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 29.40it/s]\n",
      "\u001b[32m2025-03-09 19:24:34.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 29 train 0.0721 test 0.1607 metric ['0.9563']\u001b[0m\n",
      "\u001b[32m2025-03-09 19:24:34.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.0837, current loss 0.1607.Counter 1/5.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 30/30 [01:33<00:00,  3.12s/it]\n",
      "\u001b[31m2025/03/09 19:24:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LSTM Model Training Completed! Check MLflow for results.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"Gesture_LSTM_Experiments\")\n",
    "\n",
    "# Training Loop\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"model\", \"LSTM\")\n",
    "\n",
    "    # Log Hyperparameters\n",
    "    mlflow.log_params({\n",
    "        \"input_size\": input_size,\n",
    "        \"hidden_size\": hidden_size,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"dropout\": dropout,\n",
    "        \"num_classes\": num_classes\n",
    "    })\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=train_streamer,\n",
    "        validdataloader=valid_streamer,\n",
    "        scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    trainer.loop()\n",
    "\n",
    "    # Save Model\n",
    "    modeldir = Path(\"models\")\n",
    "    modeldir.mkdir(parents=True, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    model_path = modeldir / f\"{timestamp}_LSTM_model.pt\"\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # Log Model in MLflow\n",
    "    mlflow.pytorch.log_model(model, \"LSTM\")\n",
    "    mlflow.log_artifact(model_path)\n",
    "\n",
    "mlflow.end_run()\n",
    "print(\"\\n LSTM Model Training Completed! Check MLflow for results.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with adding Conv1D layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-09 19:24:58.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/gestures\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration file loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 2600/2600 [00:08<00:00, 302.30it/s]\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 651/651 [00:02<00:00, 272.11it/s]\n",
      "\u001b[32m2025-03-09 19:25:10.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to gestures/20250309-192510\u001b[0m\n",
      "\u001b[32m2025-03-09 19:25:10.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.62it/s]\n",
      "\u001b[32m2025-03-09 19:25:15.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 2.8627 test 2.6219 metric ['0.1625']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 28.89it/s]\n",
      "\u001b[32m2025-03-09 19:25:18.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 2.3005 test 2.0786 metric ['0.2891']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 30.78it/s]\n",
      "\u001b[32m2025-03-09 19:25:21.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 1.9988 test 1.6899 metric ['0.3937']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 27.55it/s]\n",
      "\u001b[32m2025-03-09 19:25:24.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 1.6554 test 1.3935 metric ['0.4375']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 25.26it/s]\n",
      "\u001b[32m2025-03-09 19:25:28.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 1.2680 test 1.0778 metric ['0.5375']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 21.88it/s]\n",
      "\u001b[32m2025-03-09 19:25:32.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 5 train 1.1249 test 1.0146 metric ['0.5719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.99it/s]\n",
      "\u001b[32m2025-03-09 19:25:36.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 6 train 0.9426 test 0.7768 metric ['0.6500']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.06it/s]\n",
      "\u001b[32m2025-03-09 19:25:40.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 7 train 0.8225 test 0.7532 metric ['0.7188']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 23.21it/s]\n",
      "\u001b[32m2025-03-09 19:25:44.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 8 train 0.6846 test 0.5713 metric ['0.7844']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.25it/s]\n",
      "\u001b[32m2025-03-09 19:25:48.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 9 train 0.5999 test 0.5820 metric ['0.7937']\u001b[0m\n",
      "\u001b[32m2025-03-09 19:25:48.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.5713, current loss 0.5820.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 26.25it/s]\n",
      "\u001b[32m2025-03-09 19:25:52.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 10 train 0.5161 test 0.4601 metric ['0.8609']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 27.90it/s]\n",
      "\u001b[32m2025-03-09 19:25:55.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 11 train 0.4135 test 0.3754 metric ['0.8797']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 26.34it/s]\n",
      "\u001b[32m2025-03-09 19:25:59.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 12 train 0.3274 test 0.2566 metric ['0.9297']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 26.26it/s]\n",
      "\u001b[32m2025-03-09 19:26:02.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 13 train 0.2762 test 0.2840 metric ['0.9344']\u001b[0m\n",
      "\u001b[32m2025-03-09 19:26:02.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.2566, current loss 0.2840.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 24.69it/s]\n",
      "\u001b[32m2025-03-09 19:26:06.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 14 train 0.2328 test 0.1618 metric ['0.9547']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 24.54it/s]\n",
      "\u001b[32m2025-03-09 19:26:10.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 15 train 0.1539 test 0.1420 metric ['0.9578']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 24.69it/s]\n",
      "\u001b[32m2025-03-09 19:26:13.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 16 train 0.1240 test 0.1163 metric ['0.9719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:02<00:00, 27.26it/s]\n",
      "\u001b[32m2025-03-09 19:26:17.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 17 train 0.1194 test 0.1158 metric ['0.9688']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 26.67it/s]\n",
      "\u001b[32m2025-03-09 19:26:20.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 18 train 0.1684 test 0.1516 metric ['0.9563']\u001b[0m\n",
      "\u001b[32m2025-03-09 19:26:20.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.1158, current loss 0.1516.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 26.24it/s]\n",
      "\u001b[32m2025-03-09 19:26:24.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 19 train 0.1212 test 0.1120 metric ['0.9812']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 26.43it/s]\n",
      "\u001b[32m2025-03-09 19:26:27.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 20 train 0.0836 test 0.0676 metric ['0.9859']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 25.07it/s]\n",
      "\u001b[32m2025-03-09 19:26:31.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 21 train 0.0722 test 0.0574 metric ['0.9859']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 23.65it/s]\n",
      "\u001b[32m2025-03-09 19:26:34.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 22 train 0.0660 test 0.0612 metric ['0.9812']\u001b[0m\n",
      "\u001b[32m2025-03-09 19:26:34.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.0574, current loss 0.0612.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 20.79it/s]\n",
      "\u001b[32m2025-03-09 19:26:39.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 23 train 0.0532 test 0.0492 metric ['0.9844']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 23.96it/s]\n",
      "\u001b[32m2025-03-09 19:26:43.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 24 train 0.0423 test 0.0490 metric ['0.9859']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 25.47it/s]\n",
      "\u001b[32m2025-03-09 19:26:47.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 25 train 0.0585 test 0.0582 metric ['0.9828']\u001b[0m\n",
      "\u001b[32m2025-03-09 19:26:47.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.0490, current loss 0.0582.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 25.53it/s]\n",
      "\u001b[32m2025-03-09 19:26:50.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 26 train 0.0959 test 0.1095 metric ['0.9656']\u001b[0m\n",
      "\u001b[32m2025-03-09 19:26:50.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.0490, current loss 0.1095.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 26.07it/s]\n",
      "\u001b[32m2025-03-09 19:26:54.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 27 train 0.0606 test 0.0581 metric ['0.9828']\u001b[0m\n",
      "\u001b[32m2025-03-09 19:26:54.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.0490, current loss 0.0581.Counter 3/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.84it/s]\n",
      "\u001b[32m2025-03-09 19:26:57.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 28 train 0.0384 test 0.0689 metric ['0.9797']\u001b[0m\n",
      "\u001b[32m2025-03-09 19:26:57.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.0490, current loss 0.0689.Counter 4/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 26.67it/s]\n",
      "\u001b[32m2025-03-09 19:27:01.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 29 train 0.1879 test 0.0325 metric ['0.9938']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 30/30 [01:50<00:00,  3.69s/it]\n",
      "\u001b[31m2025/03/09 19:27:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conv1D Model Training Completed! Check MLflow for results.\n"
     ]
    }
   ],
   "source": [
    "import gin\n",
    "import os\n",
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from mltrainer import Trainer, TrainerSettings, ReportTypes, metrics\n",
    "from mltrainer.preprocessors import PaddedPreprocessor\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "\n",
    "# Define the ConvLSTMModel with Conv1D + LSTM\n",
    "class ConvLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout, conv_filters, kernel_size):\n",
    "        super(ConvLSTMModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "        self.conv_filters = conv_filters\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        # Conv1D layer before LSTM\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_size, out_channels=conv_filters, kernel_size=kernel_size, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(conv_filters, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Rearrange dimensions for Conv1D: (batch, seq_len, input_size) -> (batch, input_size, seq_len)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        # Rearrange back: (batch, input_size, seq_len) -> (batch, seq_len, conv_filters)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # Use last time-step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Register the model as configurable with gin\n",
    "gin.external_configurable(ConvLSTMModel)\n",
    "\n",
    "# Load the gin configuration file\n",
    "gin.clear_config()\n",
    "gin.enter_interactive_mode()\n",
    "try:\n",
    "    gin.parse_config_file(\"gestures_1d.gin\")\n",
    "    print(\"Configuration file loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing configuration file: {e}\")\n",
    "\n",
    "# Define preprocessor and dataset\n",
    "preprocessor = PaddedPreprocessor()\n",
    "gesturesdatasetfactory = DatasetFactoryProvider.create_factory(DatasetType.GESTURES)\n",
    "streamers = gesturesdatasetfactory.create_datastreamer(batchsize=32, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Retrieve hyperparameters from gin\n",
    "input_size   = gin.query_parameter(\"ConvLSTMModel.input_size\")\n",
    "hidden_size  = gin.query_parameter(\"ConvLSTMModel.hidden_size\")\n",
    "num_layers   = gin.query_parameter(\"ConvLSTMModel.num_layers\")\n",
    "dropout      = gin.query_parameter(\"ConvLSTMModel.dropout\")\n",
    "num_classes  = gin.query_parameter(\"ConvLSTMModel.num_classes\")\n",
    "conv_filters = gin.query_parameter(\"ConvLSTMModel.conv_filters\")\n",
    "kernel_size  = gin.query_parameter(\"ConvLSTMModel.kernel_size\")\n",
    "\n",
    "# Initialize model\n",
    "model = ConvLSTMModel(input_size, hidden_size, num_layers, num_classes, dropout, conv_filters, kernel_size).to(device)\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Pass the scheduler as a class instead of an instance\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau\n",
    "\n",
    "# Define TrainerSettings with updated early stopping settings (removed \"mode\")\n",
    "settings = TrainerSettings(\n",
    "    epochs=30,\n",
    "    metrics=[metrics.Accuracy()],\n",
    "    logdir=Path(\"gestures\"),\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.GIN, ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "    scheduler_kwargs={\"mode\": \"min\", \"factor\": 0.1, \"patience\": 5},\n",
    "    earlystop_kwargs={\n",
    "        \"patience\": 10  # Removed \"early_stopping_save\"\n",
    "    },\n",
    "    optimizer_kwargs={\"lr\": 0.001}\n",
    ")\n",
    "\n",
    "\n",
    "# Set MLflow tracking\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"Gesture_ConvLSTM_Experiments\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"model\", \"ConvLSTM\")\n",
    "    mlflow.log_params({\n",
    "        \"input_size\": input_size,\n",
    "        \"hidden_size\": hidden_size,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"dropout\": dropout,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"conv_filters\": conv_filters,\n",
    "        \"kernel_size\": kernel_size\n",
    "    })\n",
    "\n",
    "    # Pass the optimizer as the class (optim.Adam) so Trainer can instantiate it internally\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optim.Adam,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=scheduler,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    trainer.loop()\n",
    "\n",
    "    # Save trained model\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    model_path = Path(\"models\") / f\"{timestamp}_ConvLSTM_model.pt\"\n",
    "    os.makedirs(model_path.parent, exist_ok=True)\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    mlflow.pytorch.log_model(model, \"ConvLSTM\")\n",
    "\n",
    "mlflow.end_run()\n",
    "\n",
    "print(\"\\nConv1D Model Training Completed! Check MLflow for results.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
