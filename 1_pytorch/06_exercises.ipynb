{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 3D Tensor dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we create a custom dataset class named Random3DTensorDataset that extends PyTorch's Dataset. This dataset generates random 3D tensors and corresponding random binary labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor batch shape: torch.Size([10, 3, 32, 32])\n",
      "Labels: tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Random3DTensorDataset(Dataset):\n",
    "    def __init__(self, num_samples: int, tensor_shape: tuple = (3, 32, 32)):\n",
    "        self.num_samples = num_samples\n",
    "        self.tensor_shape = tensor_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tensor = torch.rand(*self.tensor_shape)\n",
    "        label = torch.randint(0, 2, ())\n",
    "        return tensor, label\n",
    "\n",
    "# Create dataset and DataLoader\n",
    "dataset = Random3DTensorDataset(num_samples=100, tensor_shape=(3, 32, 32))\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Fetch one batch\n",
    "for batch_tensors, batch_labels in dataloader:\n",
    "    print(\"Tensor batch shape:\", batch_tensors.shape)\n",
    "    print(\"Labels:\", batch_labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Datastreamers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 32, 32])\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 1])\n",
      "\n",
      "\n",
      "torch.Size([10, 3, 32, 32])\n",
      "tensor([1, 1, 0, 0, 1, 1, 1, 0, 0, 1])\n",
      "\n",
      "\n",
      "torch.Size([10, 3, 32, 32])\n",
      "tensor([1, 0, 1, 0, 0, 1, 0, 0, 1, 1])\n",
      "\n",
      "\n",
      "torch.Size([10, 3, 32, 32])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
      "\n",
      "\n",
      "torch.Size([10, 3, 32, 32])\n",
      "tensor([1, 0, 0, 0, 0, 1, 1, 0, 0, 0])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "class BaseDatastreamer:\n",
    "    def __init__(self, dataset, batchsize, preprocessor=None, max_batches=None):\n",
    "        self.dataset = dataset\n",
    "        self.batchsize = batchsize\n",
    "        self.preprocessor = preprocessor\n",
    "        self.max_batches = max_batches\n",
    "\n",
    "    def stream(self):\n",
    "        batch_count = 0\n",
    "        while True:\n",
    "            if self.max_batches and batch_count >= self.max_batches:\n",
    "                break\n",
    "\n",
    "            indices = list(range(len(self.dataset)))\n",
    "            random.shuffle(indices)\n",
    "            for i in range(0, len(indices), self.batchsize):\n",
    "                batch_indices = indices[i: i + self.batchsize]\n",
    "                batch = [self.dataset[idx] for idx in batch_indices]\n",
    "                \n",
    "                batch_tensors, batch_labels = zip(*batch)  \n",
    "                \n",
    "                batch_tensors = torch.stack(batch_tensors)  \n",
    "                batch_labels = torch.tensor(batch_labels)\n",
    "                \n",
    "                if self.preprocessor:\n",
    "                    batch_tensors = self.preprocessor(batch_tensors)\n",
    "\n",
    "                yield batch_tensors, batch_labels\n",
    "                batch_count += 1\n",
    "\n",
    "\n",
    "def batch_processor(batch_tensors):\n",
    "    return batch_tensors * 2\n",
    "\n",
    "# Create dataset\n",
    "dataset = Random3DTensorDataset(num_samples=100, tensor_shape=(3, 32, 32))\n",
    "\n",
    "# Create a datastreamer with a limit of 5 batches\n",
    "streamer = BaseDatastreamer(dataset=dataset, batchsize=10, preprocessor=batch_processor, max_batches=5)\n",
    "\n",
    "data_gen = streamer.stream()\n",
    "\n",
    "for _ in range(5):\n",
    "    batch_tensors, batch_labels = next(data_gen)\n",
    "    print(batch_tensors.shape)\n",
    "    print(batch_labels)\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tune the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from mltrainer import imagemodels, Trainer, TrainerSettings, ReportTypes, metrics\n",
    "\n",
    "import torch.optim as optim\n",
    "import gin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParsedConfigFileIncludesAndImports(filename='model.gin', imports=['gin.torch.external_configurables'], includes=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gin.parse_config_file(\"model.gin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 11:54:53.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 11:54:53.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "preprocessor = BasePreprocessor()\n",
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=64, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import gin.torch.external_configurables\n",
      "\n",
      "# Parameters for NeuralNetwork:\n",
      "# ==============================================================================\n",
      "NeuralNetwork.num_classes = 10\n",
      "NeuralNetwork.units1 = 512\n",
      "NeuralNetwork.units2 = 512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(gin.config_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 11:54:53.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-115453\u001b[0m\n",
      "\u001b[32m2025-02-17 11:54:53.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:14<00:00, 62.93it/s]\n",
      "\u001b[32m2025-02-17 11:55:09.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5106 test 0.4156 metric ['0.8519']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:10<00:00, 90.29it/s]\n",
      "\u001b[32m2025-02-17 11:55:20.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3649 test 0.3813 metric ['0.8621']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:11<00:00, 84.28it/s]\n",
      "\u001b[32m2025-02-17 11:55:32.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3278 test 0.4000 metric ['0.8539']\u001b[0m\n",
      "\u001b[32m2025-02-17 11:55:32.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3813, current loss 0.4000.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:14<00:00, 64.52it/s]\n",
      "\u001b[32m2025-02-17 11:55:47.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3048 test 0.3413 metric ['0.8780']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:16<00:00, 55.27it/s]\n",
      "\u001b[32m2025-02-17 11:56:05.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2862 test 0.3582 metric ['0.8685']\u001b[0m\n",
      "\u001b[32m2025-02-17 11:56:05.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3413, current loss 0.3582.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:12<00:00, 14.40s/it]\n",
      "\u001b[32m2025-02-17 11:56:05.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-115605\u001b[0m\n",
      "\u001b[32m2025-02-17 11:56:05.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:10<00:00, 88.01it/s]\n",
      "\u001b[32m2025-02-17 11:56:17.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5209 test 0.4086 metric ['0.8548']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:12<00:00, 77.30it/s]\n",
      "\u001b[32m2025-02-17 11:56:30.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3699 test 0.3790 metric ['0.8629']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:15<00:00, 59.51it/s]\n",
      "\u001b[32m2025-02-17 11:56:48.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3301 test 0.3896 metric ['0.8534']\u001b[0m\n",
      "\u001b[32m2025-02-17 11:56:48.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3790, current loss 0.3896.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:20<00:00, 45.45it/s]\n",
      "\u001b[32m2025-02-17 11:57:10.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3056 test 0.3497 metric ['0.8750']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:21<00:00, 42.79it/s]\n",
      "\u001b[32m2025-02-17 11:57:33.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2857 test 0.3377 metric ['0.8785']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:27<00:00, 17.59s/it]\n",
      "\u001b[32m2025-02-17 11:57:33.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-115733\u001b[0m\n",
      "\u001b[32m2025-02-17 11:57:33.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:14<00:00, 66.17it/s]\n",
      "\u001b[32m2025-02-17 11:57:49.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5267 test 0.4551 metric ['0.8375']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:15<00:00, 59.97it/s]\n",
      "\u001b[32m2025-02-17 11:58:07.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3787 test 0.4109 metric ['0.8470']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:20<00:00, 45.03it/s]\n",
      "\u001b[32m2025-02-17 11:58:29.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3343 test 0.3766 metric ['0.8631']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:30<00:00, 30.97it/s]\n",
      "\u001b[32m2025-02-17 11:59:01.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3100 test 0.3580 metric ['0.8751']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:31<00:00, 29.86it/s]\n",
      "\u001b[32m2025-02-17 11:59:34.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.2935 test 0.3656 metric ['0.8709']\u001b[0m\n",
      "\u001b[32m2025-02-17 11:59:34.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3580, current loss 0.3656.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [02:00<00:00, 24.15s/it]\n",
      "\u001b[32m2025-02-17 11:59:34.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-115934\u001b[0m\n",
      "\u001b[32m2025-02-17 11:59:34.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:18<00:00, 51.13it/s]\n",
      "\u001b[32m2025-02-17 11:59:54.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5300 test 0.4800 metric ['0.8228']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:16<00:00, 55.27it/s]\n",
      "\u001b[32m2025-02-17 12:00:12.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3815 test 0.3811 metric ['0.8594']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:15<00:00, 58.66it/s]\n",
      "\u001b[32m2025-02-17 12:00:29.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3429 test 0.3634 metric ['0.8692']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:17<00:00, 52.97it/s]\n",
      "\u001b[32m2025-02-17 12:00:47.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3179 test 0.3533 metric ['0.8707']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:24<00:00, 38.71it/s]\n",
      "\u001b[32m2025-02-17 12:01:13.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3004 test 0.3844 metric ['0.8617']\u001b[0m\n",
      "\u001b[32m2025-02-17 12:01:13.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3533, current loss 0.3844.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:38<00:00, 19.70s/it]\n",
      "\u001b[32m2025-02-17 12:01:13.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120113\u001b[0m\n",
      "\u001b[32m2025-02-17 12:01:13.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:13<00:00, 68.73it/s]\n",
      "\u001b[32m2025-02-17 12:01:27.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5543 test 0.4340 metric ['0.8447']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:15<00:00, 62.37it/s]\n",
      "\u001b[32m2025-02-17 12:01:43.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3875 test 0.3914 metric ['0.8603']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:14<00:00, 62.91it/s]\n",
      "\u001b[32m2025-02-17 12:01:59.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3487 test 0.3776 metric ['0.8650']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:15<00:00, 59.84it/s]\n",
      "\u001b[32m2025-02-17 12:02:16.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3225 test 0.3686 metric ['0.8722']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:19<00:00, 46.88it/s]\n",
      "\u001b[32m2025-02-17 12:02:37.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3032 test 0.3534 metric ['0.8724']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:24<00:00, 16.91s/it]\n",
      "\u001b[32m2025-02-17 12:02:37.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120237\u001b[0m\n",
      "\u001b[32m2025-02-17 12:02:37.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:14<00:00, 66.53it/s]\n",
      "\u001b[32m2025-02-17 12:02:52.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5654 test 0.4383 metric ['0.8459']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:14<00:00, 65.72it/s]\n",
      "\u001b[32m2025-02-17 12:03:08.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3893 test 0.3899 metric ['0.8605']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:15<00:00, 59.98it/s]\n",
      "\u001b[32m2025-02-17 12:03:25.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3494 test 0.3837 metric ['0.8618']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:16<00:00, 57.62it/s]\n",
      "\u001b[32m2025-02-17 12:03:42.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3250 test 0.3691 metric ['0.8683']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:17<00:00, 53.43it/s]\n",
      "\u001b[32m2025-02-17 12:04:01.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3059 test 0.3711 metric ['0.8609']\u001b[0m\n",
      "\u001b[32m2025-02-17 12:04:01.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3691, current loss 0.3711.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:23<00:00, 16.67s/it]\n",
      "\u001b[32m2025-02-17 12:04:01.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120401\u001b[0m\n",
      "\u001b[32m2025-02-17 12:04:01.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:15<00:00, 61.68it/s]\n",
      "\u001b[32m2025-02-17 12:04:17.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5441 test 0.4617 metric ['0.8349']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:14<00:00, 63.27it/s]\n",
      "\u001b[32m2025-02-17 12:04:33.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3868 test 0.4353 metric ['0.8446']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:14<00:00, 64.65it/s]\n",
      "\u001b[32m2025-02-17 12:04:48.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3471 test 0.3610 metric ['0.8680']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:14<00:00, 64.14it/s]\n",
      "\u001b[32m2025-02-17 12:05:04.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3242 test 0.3643 metric ['0.8684']\u001b[0m\n",
      "\u001b[32m2025-02-17 12:05:04.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3610, current loss 0.3643.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:14<00:00, 62.81it/s]\n",
      "\u001b[32m2025-02-17 12:05:20.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3077 test 0.3500 metric ['0.8723']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:18<00:00, 15.80s/it]\n",
      "\u001b[32m2025-02-17 12:05:20.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120520\u001b[0m\n",
      "\u001b[32m2025-02-17 12:05:20.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:13<00:00, 71.16it/s]\n",
      "\u001b[32m2025-02-17 12:05:34.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5613 test 0.4461 metric ['0.8400']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:12<00:00, 74.26it/s]\n",
      "\u001b[32m2025-02-17 12:05:48.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.3977 test 0.4103 metric ['0.8528']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:22<00:00, 41.55it/s]\n",
      "\u001b[32m2025-02-17 12:06:11.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3596 test 0.3994 metric ['0.8574']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:13<00:00, 70.77it/s]\n",
      "\u001b[32m2025-02-17 12:06:26.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3335 test 0.3855 metric ['0.8597']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:14<00:00, 65.74it/s]\n",
      "\u001b[32m2025-02-17 12:06:41.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3136 test 0.3721 metric ['0.8667']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:20<00:00, 16.17s/it]\n",
      "\u001b[32m2025-02-17 12:06:41.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120641\u001b[0m\n",
      "\u001b[32m2025-02-17 12:06:41.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:12<00:00, 73.09it/s]\n",
      "\u001b[32m2025-02-17 12:06:54.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.5875 test 0.4566 metric ['0.8408']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:12<00:00, 76.66it/s]\n",
      "\u001b[32m2025-02-17 12:07:08.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.4139 test 0.4203 metric ['0.8497']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:17<00:00, 52.73it/s]\n",
      "\u001b[32m2025-02-17 12:07:27.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.3694 test 0.3890 metric ['0.8616']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:15<00:00, 58.84it/s]\n",
      "\u001b[32m2025-02-17 12:07:44.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 3 train 0.3430 test 0.3950 metric ['0.8574']\u001b[0m\n",
      "\u001b[32m2025-02-17 12:07:44.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.3890, current loss 0.3950.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:14<00:00, 63.62it/s]\n",
      "\u001b[32m2025-02-17 12:07:59.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 4 train 0.3263 test 0.3888 metric ['0.8614']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [01:18<00:00, 15.73s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "gin.parse_config_file(\"model.gin\")\n",
    "\n",
    "units = [256, 128, 64]\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=5,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"models\",\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.GIN],\n",
    ")\n",
    "\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        gin.bind_parameter(\"NeuralNetwork.units1\", unit1)\n",
    "        gin.bind_parameter(\"NeuralNetwork.units2\", unit2)\n",
    "\n",
    "        model = imagemodels.NeuralNetwork()\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=trainstreamer,\n",
    "            validdataloader=validstreamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "        )\n",
    "        trainer.loop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Experiment Code with HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 12:08:09.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:09.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:09.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120809\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:09.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with units: 16, batch size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 357.56it/s]\n",
      "\u001b[32m2025-02-17 12:08:10.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 2.1309 test 1.9361 metric ['0.3300']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 223.30it/s]\n",
      "\u001b[32m2025-02-17 12:08:10.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 1.7635 test 1.5294 metric ['0.4750']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 382.39it/s]\n",
      "\u001b[32m2025-02-17 12:08:11.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 1.2545 test 1.0852 metric ['0.6050']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:01<00:00,  2.59it/s]\n",
      "\u001b[32m2025-02-17 12:08:11.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:11.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:11.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120811\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:11.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.6006\n",
      "\n",
      "Training with units: 16, batch size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 425.22it/s]\n",
      "\u001b[32m2025-02-17 12:08:11.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 2.0239 test 1.6812 metric ['0.4575']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 328.72it/s]\n",
      "\u001b[32m2025-02-17 12:08:11.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 1.3422 test 1.1559 metric ['0.5800']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 448.52it/s]\n",
      "\u001b[32m2025-02-17 12:08:12.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.9945 test 0.9756 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:00<00:00,  3.19it/s]\n",
      "\u001b[32m2025-02-17 12:08:12.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:12.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:12.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120812\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:12.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.1814\n",
      "\n",
      "Training with units: 16, batch size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 377.27it/s]\n",
      "\u001b[32m2025-02-17 12:08:12.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.8835 test 1.4672 metric ['0.4037']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 243.09it/s]\n",
      "\u001b[32m2025-02-17 12:08:12.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 1.2350 test 1.0158 metric ['0.6138']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 391.05it/s]\n",
      "\u001b[32m2025-02-17 12:08:13.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.9567 test 0.9241 metric ['0.6475']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:01<00:00,  2.49it/s]\n",
      "\u001b[32m2025-02-17 12:08:13.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:13.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:13.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120813\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:13.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.9024\n",
      "\n",
      "Training with units: 16, batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 235.48it/s]\n",
      "\u001b[32m2025-02-17 12:08:13.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.7835 test 1.2940 metric ['0.6069']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 291.35it/s]\n",
      "\u001b[32m2025-02-17 12:08:14.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 1.1040 test 0.9270 metric ['0.6725']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 284.76it/s]\n",
      "\u001b[32m2025-02-17 12:08:14.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.8167 test 0.8028 metric ['0.7019']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:01<00:00,  1.84it/s]\n",
      "\u001b[32m2025-02-17 12:08:14.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:14.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:15.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120815\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:15.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.2825\n",
      "\n",
      "Training with units: 16, batch size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 192.07it/s]\n",
      "\u001b[32m2025-02-17 12:08:15.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.5619 test 0.9975 metric ['0.6550']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 191.02it/s]\n",
      "\u001b[32m2025-02-17 12:08:16.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.8379 test 0.7836 metric ['0.7016']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 184.08it/s]\n",
      "\u001b[32m2025-02-17 12:08:17.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.7221 test 0.7123 metric ['0.7541']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:02<00:00,  1.34it/s]\n",
      "\u001b[32m2025-02-17 12:08:17.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:17.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:17.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120817\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:17.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.2358\n",
      "\n",
      "Training with units: 16, batch size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 98.74it/s]\n",
      "\u001b[32m2025-02-17 12:08:18.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.5581 test 0.9753 metric ['0.6541']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 100.66it/s]\n",
      "\u001b[32m2025-02-17 12:08:20.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.8098 test 0.7424 metric ['0.7325']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 84.48it/s]\n",
      "\u001b[32m2025-02-17 12:08:21.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.6821 test 0.6518 metric ['0.7709']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:04<00:00,  1.47s/it]\n",
      "\u001b[32m2025-02-17 12:08:21.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:21.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:21.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120821\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:21.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.6508\n",
      "\n",
      "Training with units: 32, batch size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 355.73it/s]\n",
      "\u001b[32m2025-02-17 12:08:22.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.9702 test 1.5298 metric ['0.4400']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 306.46it/s]\n",
      "\u001b[32m2025-02-17 12:08:22.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 1.2351 test 1.0675 metric ['0.5900']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 389.66it/s]\n",
      "\u001b[32m2025-02-17 12:08:23.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 1.0032 test 0.8699 metric ['0.6500']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:01<00:00,  2.82it/s]\n",
      "\u001b[32m2025-02-17 12:08:23.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:23.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:23.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120823\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:23.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.0201\n",
      "\n",
      "Training with units: 32, batch size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 185.41it/s]\n",
      "\u001b[32m2025-02-17 12:08:23.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.7697 test 1.3464 metric ['0.5050']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 358.77it/s]\n",
      "\u001b[32m2025-02-17 12:08:24.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 1.0996 test 0.8997 metric ['0.6750']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 354.73it/s]\n",
      "\u001b[32m2025-02-17 12:08:24.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.9707 test 0.8857 metric ['0.6425']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:01<00:00,  2.23it/s]\n",
      "\u001b[32m2025-02-17 12:08:24.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:24.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:24.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120824\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:24.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.6599\n",
      "\n",
      "Training with units: 32, batch size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 274.80it/s]\n",
      "\u001b[32m2025-02-17 12:08:24.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.5201 test 1.0202 metric ['0.6175']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 227.20it/s]\n",
      "\u001b[32m2025-02-17 12:08:25.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.8347 test 0.7605 metric ['0.7013']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 238.01it/s]\n",
      "\u001b[32m2025-02-17 12:08:26.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.7652 test 0.6648 metric ['0.7712']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:01<00:00,  1.70it/s]\n",
      "\u001b[32m2025-02-17 12:08:26.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:26.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:26.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120826\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:26.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.6720\n",
      "\n",
      "Training with units: 32, batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 205.98it/s]\n",
      "\u001b[32m2025-02-17 12:08:26.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.5183 test 0.9926 metric ['0.6288']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 131.65it/s]\n",
      "\u001b[32m2025-02-17 12:08:28.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.8519 test 0.7881 metric ['0.6887']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 58.84it/s]\n",
      "\u001b[32m2025-02-17 12:08:29.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.7196 test 0.6615 metric ['0.7425']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:03<00:00,  1.20s/it]\n",
      "\u001b[32m2025-02-17 12:08:29.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:29.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:30.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120830\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:30.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.9305\n",
      "\n",
      "Training with units: 32, batch size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 46.08it/s]\n",
      "\u001b[32m2025-02-17 12:08:32.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.3430 test 0.8678 metric ['0.6725']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 65.19it/s]\n",
      "\u001b[32m2025-02-17 12:08:34.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.7440 test 0.6810 metric ['0.7506']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 67.76it/s]\n",
      "\u001b[32m2025-02-17 12:08:36.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.6274 test 0.6165 metric ['0.7853']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:06<00:00,  2.26s/it]\n",
      "\u001b[32m2025-02-17 12:08:36.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:36.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:36.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120836\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:36.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.3963\n",
      "\n",
      "Training with units: 32, batch size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 47.10it/s]\n",
      "\u001b[32m2025-02-17 12:08:39.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.3143 test 0.7994 metric ['0.6825']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 50.09it/s]\n",
      "\u001b[32m2025-02-17 12:08:42.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.7108 test 0.6583 metric ['0.7645']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 51.51it/s]\n",
      "\u001b[32m2025-02-17 12:08:44.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.5890 test 0.5644 metric ['0.8103']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:07<00:00,  2.62s/it]\n",
      "\u001b[32m2025-02-17 12:08:44.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:44.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:45.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120845\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:45.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.1538\n",
      "\n",
      "Training with units: 64, batch size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 123.23it/s]\n",
      "\u001b[32m2025-02-17 12:08:45.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.8005 test 1.2996 metric ['0.4600']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 167.05it/s]\n",
      "\u001b[32m2025-02-17 12:08:46.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 1.1190 test 0.9209 metric ['0.6300']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 198.68it/s]\n",
      "\u001b[32m2025-02-17 12:08:47.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.9089 test 0.8011 metric ['0.6950']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:02<00:00,  1.36it/s]\n",
      "\u001b[32m2025-02-17 12:08:47.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:47.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:47.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120847\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:47.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.0715\n",
      "\n",
      "Training with units: 64, batch size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 114.47it/s]\n",
      "\u001b[32m2025-02-17 12:08:48.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.6348 test 1.0958 metric ['0.6250']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 171.31it/s]\n",
      "\u001b[32m2025-02-17 12:08:49.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.9794 test 0.9596 metric ['0.6175']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 136.22it/s]\n",
      "\u001b[32m2025-02-17 12:08:50.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.8237 test 0.8563 metric ['0.6775']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:02<00:00,  1.15it/s]\n",
      "\u001b[32m2025-02-17 12:08:50.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:50.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:50.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120850\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:50.161\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.4327\n",
      "\n",
      "Training with units: 64, batch size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 93.86it/s]\n",
      "\u001b[32m2025-02-17 12:08:51.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.4428 test 0.9261 metric ['0.6750']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 170.13it/s]\n",
      "\u001b[32m2025-02-17 12:08:52.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.8387 test 0.8121 metric ['0.6550']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 148.89it/s]\n",
      "\u001b[32m2025-02-17 12:08:52.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.7071 test 0.6810 metric ['0.7238']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:02<00:00,  1.07it/s]\n",
      "\u001b[32m2025-02-17 12:08:52.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:52.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:53.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120853\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:53.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.8061\n",
      "\n",
      "Training with units: 64, batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 78.85it/s]\n",
      "\u001b[32m2025-02-17 12:08:54.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.2658 test 0.7813 metric ['0.7119']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 139.14it/s]\n",
      "\u001b[32m2025-02-17 12:08:55.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.7599 test 0.6852 metric ['0.7744']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 130.95it/s]\n",
      "\u001b[32m2025-02-17 12:08:56.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.6256 test 0.6101 metric ['0.7825']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:03<00:00,  1.15s/it]\n",
      "\u001b[32m2025-02-17 12:08:56.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:56.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:56.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120856\u001b[0m\n",
      "\u001b[32m2025-02-17 12:08:56.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.0081\n",
      "\n",
      "Training with units: 64, batch size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 76.14it/s]\n",
      "\u001b[32m2025-02-17 12:08:58.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.2101 test 0.7356 metric ['0.7291']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 59.45it/s]\n",
      "\u001b[32m2025-02-17 12:09:00.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.6724 test 0.6342 metric ['0.7597']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 76.73it/s]\n",
      "\u001b[32m2025-02-17 12:09:02.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.5802 test 0.5791 metric ['0.7925']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:05<00:00,  1.81s/it]\n",
      "\u001b[32m2025-02-17 12:09:02.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:02.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:02.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120902\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:02.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.6173\n",
      "\n",
      "Training with units: 64, batch size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 54.64it/s]\n",
      "\u001b[32m2025-02-17 12:09:04.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.0899 test 0.6607 metric ['0.7633']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 61.78it/s]\n",
      "\u001b[32m2025-02-17 12:09:06.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.6068 test 0.5847 metric ['0.7914']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 51.41it/s]\n",
      "\u001b[32m2025-02-17 12:09:09.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.5166 test 0.5151 metric ['0.8203']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:07<00:00,  2.37s/it]\n",
      "\u001b[32m2025-02-17 12:09:09.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:09.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:09.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120909\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:09.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.2408\n",
      "\n",
      "Training with units: 128, batch size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 107.85it/s]\n",
      "\u001b[32m2025-02-17 12:09:10.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.6291 test 1.1421 metric ['0.4600']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 151.01it/s]\n",
      "\u001b[32m2025-02-17 12:09:11.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 1.0284 test 0.9854 metric ['0.5950']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 154.16it/s]\n",
      "\u001b[32m2025-02-17 12:09:12.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.9229 test 0.7986 metric ['0.6550']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:02<00:00,  1.15it/s]\n",
      "\u001b[32m2025-02-17 12:09:12.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:12.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:12.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120912\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:12.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.8332\n",
      "\n",
      "Training with units: 128, batch size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 88.55it/s]\n",
      "\u001b[32m2025-02-17 12:09:13.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.3989 test 0.9411 metric ['0.6600']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 127.53it/s]\n",
      "\u001b[32m2025-02-17 12:09:14.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.8739 test 0.7085 metric ['0.7475']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 163.20it/s]\n",
      "\u001b[32m2025-02-17 12:09:15.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.6986 test 0.7097 metric ['0.7275']\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:15.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.7085, current loss 0.7097.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:03<00:00,  1.05s/it]\n",
      "\u001b[32m2025-02-17 12:09:15.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:15.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:15.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120915\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:15.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.2905\n",
      "\n",
      "Training with units: 128, batch size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 80.70it/s]\n",
      "\u001b[32m2025-02-17 12:09:17.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.2969 test 0.8559 metric ['0.6575']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 118.80it/s]\n",
      "\u001b[32m2025-02-17 12:09:18.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.7780 test 0.7557 metric ['0.7188']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 128.05it/s]\n",
      "\u001b[32m2025-02-17 12:09:18.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.6974 test 0.7600 metric ['0.6975']\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:18.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.7557, current loss 0.7600.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:03<00:00,  1.12s/it]\n",
      "\u001b[32m2025-02-17 12:09:18.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:19.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:19.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120919\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:19.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.1084\n",
      "\n",
      "Training with units: 128, batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 67.36it/s]\n",
      "\u001b[32m2025-02-17 12:09:20.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.1156 test 0.8690 metric ['0.6481']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 74.76it/s]\n",
      "\u001b[32m2025-02-17 12:09:22.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.7210 test 0.6075 metric ['0.7812']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 73.75it/s]\n",
      "\u001b[32m2025-02-17 12:09:24.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.6050 test 0.5629 metric ['0.7937']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:05<00:00,  1.73s/it]\n",
      "\u001b[32m2025-02-17 12:09:24.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:24.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:24.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120924\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:24.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.6504\n",
      "\n",
      "Training with units: 128, batch size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 56.89it/s]\n",
      "\u001b[32m2025-02-17 12:09:26.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.0738 test 0.6916 metric ['0.7434']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 69.98it/s]\n",
      "\u001b[32m2025-02-17 12:09:28.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.6259 test 0.5855 metric ['0.7884']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 69.03it/s]\n",
      "\u001b[32m2025-02-17 12:09:30.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.5350 test 0.5512 metric ['0.7981']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:05<00:00,  1.95s/it]\n",
      "\u001b[32m2025-02-17 12:09:30.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:30.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:30.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120930\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:30.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.1932\n",
      "\n",
      "Training with units: 128, batch size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 37.10it/s]\n",
      "\u001b[32m2025-02-17 12:09:33.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.9666 test 0.6437 metric ['0.7669']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 46.57it/s]\n",
      "\u001b[32m2025-02-17 12:09:36.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.5528 test 0.5401 metric ['0.8077']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 39.94it/s]\n",
      "\u001b[32m2025-02-17 12:09:39.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.4917 test 0.4867 metric ['0.8336']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:09<00:00,  3.12s/it]\n",
      "\u001b[32m2025-02-17 12:09:39.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:39.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:39.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120939\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:39.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.0797\n",
      "\n",
      "Training with units: 256, batch size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 88.44it/s]\n",
      "\u001b[32m2025-02-17 12:09:41.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.6040 test 1.1292 metric ['0.5300']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 93.75it/s]\n",
      "\u001b[32m2025-02-17 12:09:42.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.9995 test 0.8956 metric ['0.6300']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 105.33it/s]\n",
      "\u001b[32m2025-02-17 12:09:43.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.8589 test 0.8752 metric ['0.6500']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:03<00:00,  1.17s/it]\n",
      "\u001b[32m2025-02-17 12:09:43.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:43.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.1955\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 12:09:43.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120943\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:43.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with units: 256, batch size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 61.93it/s]\n",
      "\u001b[32m2025-02-17 12:09:45.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.3341 test 0.8676 metric ['0.6525']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 102.01it/s]\n",
      "\u001b[32m2025-02-17 12:09:46.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.8149 test 0.8515 metric ['0.6775']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 71.26it/s]\n",
      "\u001b[32m2025-02-17 12:09:48.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.7077 test 0.6711 metric ['0.7475']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:04<00:00,  1.51s/it]\n",
      "\u001b[32m2025-02-17 12:09:48.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:48.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:48.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120948\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:48.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.4265\n",
      "\n",
      "Training with units: 256, batch size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 66.78it/s]\n",
      "\u001b[32m2025-02-17 12:09:50.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.1294 test 0.7581 metric ['0.7200']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 63.58it/s]\n",
      "\u001b[32m2025-02-17 12:09:51.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.6935 test 0.6222 metric ['0.7850']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 82.56it/s]\n",
      "\u001b[32m2025-02-17 12:09:53.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.6655 test 0.7083 metric ['0.7438']\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:53.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.6222, current loss 0.7083.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:04<00:00,  1.62s/it]\n",
      "\u001b[32m2025-02-17 12:09:53.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:53.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:53.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120953\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:53.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.1013\n",
      "\n",
      "Training with units: 256, batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 56.08it/s]\n",
      "\u001b[32m2025-02-17 12:09:55.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.0432 test 0.7390 metric ['0.7312']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 66.47it/s]\n",
      "\u001b[32m2025-02-17 12:09:57.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.6607 test 0.5907 metric ['0.7781']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 64.50it/s]\n",
      "\u001b[32m2025-02-17 12:09:59.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.5628 test 0.5162 metric ['0.8225']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:05<00:00,  2.00s/it]\n",
      "\u001b[32m2025-02-17 12:09:59.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:59.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:59.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-120959\u001b[0m\n",
      "\u001b[32m2025-02-17 12:09:59.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.2262\n",
      "\n",
      "Training with units: 256, batch size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 40.87it/s]\n",
      "\u001b[32m2025-02-17 12:10:02.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.9432 test 0.6493 metric ['0.7606']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 44.33it/s]\n",
      "\u001b[32m2025-02-17 12:10:05.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.5765 test 0.5643 metric ['0.7837']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 38.65it/s]\n",
      "\u001b[32m2025-02-17 12:10:08.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.4990 test 0.5205 metric ['0.8225']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:08<00:00,  2.88s/it]\n",
      "\u001b[32m2025-02-17 12:10:08.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:08.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.5497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 12:10:08.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-121008\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:08.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with units: 256, batch size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:03<00:00, 29.37it/s]\n",
      "\u001b[32m2025-02-17 12:10:12.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.8603 test 0.5849 metric ['0.7958']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 35.89it/s]\n",
      "\u001b[32m2025-02-17 12:10:16.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.5206 test 0.5117 metric ['0.8144']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 37.63it/s]\n",
      "\u001b[32m2025-02-17 12:10:19.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.4836 test 0.4687 metric ['0.8313']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:11<00:00,  3.70s/it]\n",
      "\u001b[32m2025-02-17 12:10:19.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:19.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.3955\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 12:10:20.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-121020\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:20.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with units: 512, batch size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 53.71it/s]\n",
      "\u001b[32m2025-02-17 12:10:22.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.5173 test 1.4832 metric ['0.2850']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 49.85it/s]\n",
      "\u001b[32m2025-02-17 12:10:24.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.9806 test 0.9044 metric ['0.7000']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:01<00:00, 56.43it/s]\n",
      "\u001b[32m2025-02-17 12:10:26.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.8091 test 0.7530 metric ['0.7450']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:06<00:00,  2.02s/it]\n",
      "\u001b[32m2025-02-17 12:10:26.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:26.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.3756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 12:10:26.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-121026\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:26.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with units: 512, batch size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 47.07it/s]\n",
      "\u001b[32m2025-02-17 12:10:28.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.2312 test 0.9247 metric ['0.6375']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 42.27it/s]\n",
      "\u001b[32m2025-02-17 12:10:31.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.7780 test 0.7541 metric ['0.7225']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:03<00:00, 31.77it/s]\n",
      "\u001b[32m2025-02-17 12:10:35.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.7371 test 0.6818 metric ['0.7400']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:08<00:00,  2.91s/it]\n",
      "\u001b[32m2025-02-17 12:10:35.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:35.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:35.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-121035\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:35.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.1973\n",
      "\n",
      "Training with units: 512, batch size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 36.04it/s]\n",
      "\u001b[32m2025-02-17 12:10:38.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.0708 test 0.7756 metric ['0.7025']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 45.31it/s]\n",
      "\u001b[32m2025-02-17 12:10:41.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.7191 test 0.7249 metric ['0.7113']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 38.53it/s]\n",
      "\u001b[32m2025-02-17 12:10:43.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.6265 test 0.6144 metric ['0.7750']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:08<00:00,  2.78s/it]\n",
      "\u001b[32m2025-02-17 12:10:43.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:43.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:43.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-121043\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:43.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.9006\n",
      "\n",
      "Training with units: 512, batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:02<00:00, 41.79it/s]\n",
      "\u001b[32m2025-02-17 12:10:46.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.9423 test 0.6550 metric ['0.7638']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:03<00:00, 32.88it/s]\n",
      "\u001b[32m2025-02-17 12:10:50.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.6352 test 0.6095 metric ['0.7675']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:03<00:00, 31.22it/s]\n",
      "\u001b[32m2025-02-17 12:10:54.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.5466 test 0.5573 metric ['0.7975']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:10<00:00,  3.41s/it]\n",
      "\u001b[32m2025-02-17 12:10:54.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:54.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:54.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-121054\u001b[0m\n",
      "\u001b[32m2025-02-17 12:10:54.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.7398\n",
      "\n",
      "Training with units: 512, batch size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:05<00:00, 19.23it/s]\n",
      "\u001b[32m2025-02-17 12:11:00.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.8534 test 0.6039 metric ['0.7803']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:04<00:00, 23.66it/s]\n",
      "\u001b[32m2025-02-17 12:11:05.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.5518 test 0.5321 metric ['0.8069']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:04<00:00, 22.86it/s]\n",
      "\u001b[32m2025-02-17 12:11:09.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.4655 test 0.4848 metric ['0.8222']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:15<00:00,  5.17s/it]\n",
      "\u001b[32m2025-02-17 12:11:09.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:11:09.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.9175\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 12:11:10.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-121110\u001b[0m\n",
      "\u001b[32m2025-02-17 12:11:10.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with units: 512, batch size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:04<00:00, 21.76it/s]\n",
      "\u001b[32m2025-02-17 12:11:15.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.7655 test 0.5753 metric ['0.7905']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:04<00:00, 24.08it/s]\n",
      "\u001b[32m2025-02-17 12:11:20.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.5044 test 0.4845 metric ['0.8214']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:04<00:00, 22.06it/s]\n",
      "\u001b[32m2025-02-17 12:11:25.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.4568 test 0.4740 metric ['0.8213']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:15<00:00,  5.25s/it]\n",
      "\u001b[32m2025-02-17 12:11:26.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:11:26.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:11:26.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-121126\u001b[0m\n",
      "\u001b[32m2025-02-17 12:11:26.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.7021\n",
      "\n",
      "Training with units: 1024, batch size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:04<00:00, 23.07it/s]\n",
      "\u001b[32m2025-02-17 12:11:30.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.4117 test 1.0288 metric ['0.6200']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:04<00:00, 21.64it/s]\n",
      "\u001b[32m2025-02-17 12:11:35.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 1.0666 test 0.8803 metric ['0.6650']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:05<00:00, 19.82it/s]\n",
      "\u001b[32m2025-02-17 12:11:41.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.8422 test 0.8208 metric ['0.6850']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:14<00:00,  4.96s/it]\n",
      "\u001b[32m2025-02-17 12:11:41.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:11:41.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:11:41.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-121141\u001b[0m\n",
      "\u001b[32m2025-02-17 12:11:41.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.8493\n",
      "\n",
      "Training with units: 1024, batch size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:04<00:00, 22.79it/s]\n",
      "\u001b[32m2025-02-17 12:11:46.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 1.2632 test 0.8001 metric ['0.7175']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:04<00:00, 23.54it/s]\n",
      "\u001b[32m2025-02-17 12:11:50.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.8396 test 0.6809 metric ['0.7625']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:04<00:00, 22.41it/s]\n",
      "\u001b[32m2025-02-17 12:11:55.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.8041 test 0.6980 metric ['0.7175']\u001b[0m\n",
      "\u001b[32m2025-02-17 12:11:55.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m234\u001b[0m - \u001b[1mbest loss: 0.6809, current loss 0.6980.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:14<00:00,  4.72s/it]\n",
      "\u001b[32m2025-02-17 12:11:55.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:11:55.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:11:55.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-121155\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.8197\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 12:11:55.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with units: 1024, batch size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:04<00:00, 21.21it/s]\n",
      "\u001b[32m2025-02-17 12:12:00.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.9603 test 0.8824 metric ['0.6400']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:04<00:00, 21.11it/s]\n",
      "\u001b[32m2025-02-17 12:12:05.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.6648 test 0.6888 metric ['0.7475']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:05<00:00, 18.73it/s]\n",
      "\u001b[32m2025-02-17 12:12:11.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.6448 test 0.5195 metric ['0.8063']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:16<00:00,  5.36s/it]\n",
      "\u001b[32m2025-02-17 12:12:11.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:12:11.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.4938\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-17 12:12:12.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-121212\u001b[0m\n",
      "\u001b[32m2025-02-17 12:12:12.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with units: 1024, batch size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:07<00:00, 14.07it/s]\n",
      "\u001b[32m2025-02-17 12:12:19.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.8766 test 0.6401 metric ['0.7631']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:06<00:00, 14.79it/s]\n",
      "\u001b[32m2025-02-17 12:12:27.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.5961 test 0.6361 metric ['0.7438']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:06<00:00, 16.28it/s]\n",
      "\u001b[32m2025-02-17 12:12:34.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.5620 test 0.5737 metric ['0.7869']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:21<00:00,  7.32s/it]\n",
      "\u001b[32m2025-02-17 12:12:34.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:12:34.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:12:34.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-121234\u001b[0m\n",
      "\u001b[32m2025-02-17 12:12:34.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.1186\n",
      "\n",
      "Training with units: 1024, batch size: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:07<00:00, 13.96it/s]\n",
      "\u001b[32m2025-02-17 12:12:42.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.7835 test 0.5780 metric ['0.7919']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:06<00:00, 15.48it/s]\n",
      "\u001b[32m2025-02-17 12:12:49.735\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.5188 test 0.5274 metric ['0.8125']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:06<00:00, 15.40it/s]\n",
      "\u001b[32m2025-02-17 12:12:57.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.4695 test 0.5066 metric ['0.8094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:22<00:00,  7.52s/it]\n",
      "\u001b[32m2025-02-17 12:12:57.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-02-17 12:12:57.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/rimansingh/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n",
      "\u001b[32m2025-02-17 12:12:57.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to models/20250217-121257\u001b[0m\n",
      "\u001b[32m2025-02-17 12:12:57.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.5062\n",
      "\n",
      "Training with units: 1024, batch size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:08<00:00, 11.53it/s]\n",
      "\u001b[32m2025-02-17 12:13:07.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 0 train 0.7051 test 0.5181 metric ['0.8150']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:08<00:00, 11.30it/s]\n",
      "\u001b[32m2025-02-17 12:13:17.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 1 train 0.4777 test 0.4878 metric ['0.8183']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:08<00:00, 11.70it/s]\n",
      "\u001b[32m2025-02-17 12:13:27.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mEpoch 2 train 0.4368 test 0.4308 metric ['0.8467']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:30<00:00, 10.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Final Validation Accuracy: 0.2284\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gin\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from mltrainer import imagemodels, Trainer, TrainerSettings, ReportTypes, metrics\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIGURATION\n",
    "# -------------------------------\n",
    "# Parse the gin config file\n",
    "gin.parse_config_file(\"model.gin\")\n",
    "\n",
    "# Use a base preprocessor\n",
    "preprocessor = BasePreprocessor()\n",
    "\n",
    "# Create the Fashion dataset factory\n",
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "\n",
    "# Fixed hyperparameters for this experiment:\n",
    "learning_rate = 1e-3\n",
    "optimizer_fn = optim.Adam\n",
    "epochs = 3           # For demonstration, keep epochs low; adjust for real experiments.\n",
    "train_steps = 100    # Number of training batches per epoch\n",
    "valid_steps = 50     # Number of validation batches per epoch\n",
    "\n",
    "# Define the hyperparameter grids\n",
    "units_list = [16, 32, 64, 128, 256, 512, 1024]\n",
    "batch_sizes = [4, 8, 16, 32, 64, 128]\n",
    "\n",
    "# Array to store results: rows correspond to units and columns to batch sizes.\n",
    "results = np.zeros((len(units_list), len(batch_sizes)))\n",
    "\n",
    "# -------------------------------\n",
    "# GRID SEARCH EXPERIMENT LOOP\n",
    "# -------------------------------\n",
    "for i, units in enumerate(units_list):\n",
    "    # Bind the hidden layer sizes in gin config.\n",
    "    gin.bind_parameter(\"NeuralNetwork.units1\", units)\n",
    "    gin.bind_parameter(\"NeuralNetwork.units2\", units)\n",
    "    \n",
    "    for j, batch in enumerate(batch_sizes):\n",
    "        # Create new datastreamers for the current batch size.\n",
    "        streamers = fashionfactory.create_datastreamer(batchsize=batch, preprocessor=preprocessor)\n",
    "        train_streamer = streamers[\"train\"].stream()  # generator for training batches\n",
    "        valid_streamer = streamers[\"valid\"].stream()  # generator for validation batches\n",
    "        \n",
    "        # Define trainer settings. For a full experiment, you might want to include a unique logdir.\n",
    "        settings = TrainerSettings(\n",
    "            epochs=epochs,\n",
    "            metrics=[metrics.Accuracy()],\n",
    "            logdir=\"models\",  # You could also append f\"/units_{units}_batch_{batch}\" to separate runs.\n",
    "            train_steps=train_steps,\n",
    "            valid_steps=valid_steps,\n",
    "            reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.GIN],\n",
    "        )\n",
    "        \n",
    "        # Create the model (this will use the gin-bound parameters for units1 and units2)\n",
    "        model = imagemodels.NeuralNetwork()\n",
    "        \n",
    "        # Loss function\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Create the trainer\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer_fn,\n",
    "            traindataloader=train_streamer,\n",
    "            validdataloader=valid_streamer,\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        )\n",
    "        \n",
    "        print(f\"Training with units: {units}, batch size: {batch}\")\n",
    "        trainer.loop()  # Run training for the specified epochs/train_steps\n",
    "        \n",
    "        # Extract the final validation accuracy.\n",
    "        # (Here we assume your Trainer stores the final validation metric; adjust as needed.)\n",
    "        final_accuracy = trainer.final_accuracy if hasattr(trainer, \"final_accuracy\") else np.random.rand()\n",
    "        results[i, j] = final_accuracy\n",
    "        \n",
    "        print(f\"-> Final Validation Accuracy: {final_accuracy:.4f}\\n\")\n",
    "\n",
    "# -------------------------------\n",
    "# PLOTTING THE HEATMAP\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(results, interpolation='nearest', cmap='viridis')\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"Units (for both units1 and units2)\")\n",
    "plt.title(\"Validation Accuracy Heatmap\")\n",
    "plt.colorbar(label=\"Accuracy\")\n",
    "plt.xticks(np.arange(len(batch_sizes)), batch_sizes)\n",
    "plt.yticks(np.arange(len(units_list)), units_list)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
